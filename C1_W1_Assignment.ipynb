{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chest X-Ray Medical Diagnosis with Deep Learning\n",
    "\n",
    "![header image](images/xray-header-image.png)\n",
    "\n",
    "Welcome to the first assignment of AI for Medical Diagnosis!\n",
    "\n",
    "In this assignment you will build a state-of-the-art chest X-ray classifier using Keras for medical image diagnosis. You will:\n",
    "- Pre-process and prepare a real-world X-ray dataset\n",
    "- Use transfer learning to retrain a DenseNet model for X-ray image classification\n",
    "- Handle class imbalance\n",
    "- Compute AUROC for ROC curve\n",
    "- Visualize model activity using GradCAMs\n",
    "\n",
    "## Table of Contents\n",
    "- [1. Import Packages and Functions](#1)\n",
    "- [2. Load the Datasets](#2)\n",
    "  - [2.1 Loading the Data](#2-1)\n",
    "  - [2.2 Preventing Data Leakage](#2-2)\n",
    "      - [Exercise 1 - check for Leakage](#Ex-1)\n",
    "  - [2.3 Preparing Images](#2-3)\n",
    "- [3. Model Development](#3)\n",
    "  - [3.1 Addressing Class Imbalance](#3-1)\n",
    "      - [Exercise 2 - compute Class Frequencies](#Ex-2)\n",
    "      - [Exercise 3 - get Weighted Loss](#Ex-3)\n",
    "  - [3.2 DenseNet121](#3-2)\n",
    "- [4. Training (Optional)](#4)\n",
    "  - [4.1 Training on the Larger Dataset](#4-1)\n",
    "- [5. Prediction and Evaluation](#5)\n",
    "  - [5.1 ROC Curve and AUROC](#5-1)\n",
    "  - [5.2 Visualizing Learning with GradCAM](#5-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Packages and Functions <a name='1'></a>\n",
    "\n",
    "We'll use:\n",
    "- `numpy`, `pandas`: Data manipulation\n",
    "- `matplotlib.pyplot`, `seaborn`: Visualization\n",
    "- `keras` (ImageDataGenerator, DenseNet121, layers, Model)\n",
    "- Custom utilities in `util.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "import util\n",
    "from public_tests import *\n",
    "from test_utils import *\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Datasets <a name='2'></a>\n",
    "\n",
    "We'll use the ChestX-ray8 dataset (see [link](https://arxiv.org/abs/1705.02315)) and subset CSV files for train, validation, and test splits. Each image contains labels for 14 pathologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_df = pd.read_csv(\"data/nih/train-small.csv\")\n",
    "valid_df = pd.read_csv(\"data/nih/valid-small.csv\")\n",
    "test_df = pd.read_csv(\"data/nih/test.csv\")\n",
    "train_df.head()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels = ['Cardiomegaly', \n",
    "          'Emphysema', \n",
    "          'Effusion', \n",
    "          'Hernia', \n",
    "          'Infiltration', \n",
    "          'Mass', \n",
    "          'Nodule', \n",
    "          'Atelectasis',\n",
    "          'Pneumothorax',\n",
    "          'Pleural_Thickening', \n",
    "          'Pneumonia', \n",
    "          'Fibrosis', \n",
    "          'Edema', \n",
    "          'Consolidation']\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preventing Data Leakage <a name='2-2'></a>\n",
    "Multiple images per patient: split is done at patient-level to avoid leakage. Let's check that now.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    df1_patients_unique = set(df1[patient_col].values)\n",
    "    df2_patients_unique = set(df2[patient_col].values)\n",
    "    patients_in_both_groups = list(df1_patients_unique.intersection(df2_patients_unique))\n",
    "    leakage = len(patients_in_both_groups) != 0\n",
    "    return leakage\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test for leakage between splits\n",
    "print(\"leakage between train and valid:\", check_for_leakage(train_df, valid_df, 'PatientId'))\n",
    "print(\"leakage between train and test:\", check_for_leakage(train_df, test_df, 'PatientId'))\n",
    "print(\"leakage between valid and test:\", check_for_leakage(valid_df, test_df, 'PatientId'))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Preparing Images <a name='2-3'></a>\n",
    "Use ImageDataGenerator to create generators for training, validation, and test sets. Training uses samplewise normalization, validation/test use statistics from training sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "    image_generator = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        directory=image_dir,\n",
    "        x_col=x_col,\n",
    "        y_col=y_cols,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        target_size=(target_w,target_h))\n",
    "    return generator\n",
    "\n",
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=image_dir, \n",
    "        x_col=\"Image\", \n",
    "        y_col=labels, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=sample_size, \n",
    "        shuffle=True, \n",
    "        target_size=(target_w, target_h))\n",
    "    data_sample = raw_train_generator.next()[0]\n",
    "    image_generator = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "    image_generator.fit(data_sample)\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=image_dir,\n",
    "        x_col=x_col,\n",
    "        y_col=y_cols,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        seed=seed,\n",
    "        target_size=(target_w,target_h))\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=image_dir,\n",
    "        x_col=x_col,\n",
    "        y_col=y_cols,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        seed=seed,\n",
    "        target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "IMAGE_DIR = \"data/nih/images-small/\"\n",
    "train_generator = get_train_generator(train_df, IMAGE_DIR, \"Image\", labels)\n",
    "valid_generator, test_generator = get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, \"Image\", labels)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Peek at a training image\n",
    "x, y = train_generator.__getitem__(0)\n",
    "plt.imshow(x[0]);\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development <a name='3'></a>\n",
    "\n",
    "### 3.1 Addressing Class Imbalance <a name='3-1'></a>\n",
    "Let's plot positive case frequency for each label.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=labels, height=np.mean(train_generator.labels, axis=0))\n",
    "plt.title(\"Frequency of Each Class\")\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 - Compute Class Frequencies <a name='Ex-2'></a>\n",
    "Calculate positive and negative frequencies for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_class_freqs(labels):\n",
    "    N = labels.shape[0]\n",
    "    positive_frequencies = np.sum(labels == 1, axis=0) / N\n",
    "    negative_frequencies = np.sum(labels == 0, axis=0) / N\n",
    "    return positive_frequencies, negative_frequencies\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "freq_pos, freq_neg = compute_class_freqs(train_generator.labels)\n",
    "freq_pos\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize positive and negative frequencies\n",
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\", data=data)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use weights to balance loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = freq_pos * pos_weights \n",
    "neg_contribution = freq_neg * neg_weights\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize weighted contributions\n",
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n",
    "                        for l,v in enumerate(neg_contribution)], ignore_index=True)\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\", data=data);\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 - Get Weighted Loss <a name='Ex-3'></a>\n",
    "Return a loss function calculating weighted loss for each batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        loss = 0.0\n",
    "        for i in range(len(pos_weights)):\n",
    "            loss += K.mean(-pos_weights[i]*K.log(y_pred[:,i]+epsilon)*y_true[:,i]-neg_weights[i]*K.log(1-y_pred[:,i]+epsilon)*(1-y_true[:,i]))\n",
    "        return loss\n",
    "    return weighted_loss\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DenseNet121 <a name='3-2'></a>\n",
    "Load pretrained DenseNet121 and add global average pooling and dense layer for multi-label sigmoid output.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_model = DenseNet121(weights='models/nih/densenet.hdf5', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training (Optional) <a name='4'></a>\n",
    "\n",
    "You may train locally using model.fit_generator, but here we load pretrained weights for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.load_weights(\"models/nih/pretrained_model.h5\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction and Evaluation <a name='5'></a>\n",
    "\n",
    "Get predictions for the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "predicted_vals = model.predict_generator(test_generator, steps = len(test_generator))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 ROC Curve and AUROC <a name='5-1'></a>\n",
    "\n",
    "Compute ROC curve and AUROC for test results.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "auc_rocs = util.get_roc_curve(labels, predicted_vals, test_generator)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Visualizing Learning with GradCAM <a name='5-2'></a>\n",
    "\n",
    "Visualize GradCAM heatmaps for model interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"data/nih/train-small.csv\")\n",
    "IMAGE_DIR = \"data/nih/images-small/\"\n",
    "labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-1])[:4]\n",
    "util.compute_gradcam(model, '00008270_015.png', IMAGE_DIR, df, labels, labels_to_show)\n",
    "util.compute_gradcam(model, '00011355_002.png', IMAGE_DIR, df, labels, labels_to_show)\n",
    "util.compute_gradcam(model, '00029855_001.png', IMAGE_DIR, df, labels, labels_to_show)\n",
    "util.compute_gradcam(model, '00005410_000.png', IMAGE_DIR, df, labels, labels_to_show)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Congratulations!\n",
    "You've completed the first assignment of AI for Medical Diagnosis. You learned data preprocessing, leakage detection, transfer learning, class balancing, AUROC evaluation, and model interpretability with GradCAMs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7"
  },
  "title": "Chest X-Ray Medical Diagnosis with Deep Learning",
  "authors": [
   {
    "name": "abla-rabia",
    "github": "abla-rabia"
   }
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
