{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2652/1*eTkBMyqdg9JodNcG_O4-Kw.jpeg\" width=\"100%\">\n",
    "[Image Source](https://medium.com/stanford-ai-for-healthcare/its-a-no-brainer-deep-learning-for-brain-mr-images-f60116397472)\n",
    "\n",
    "# Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)\n",
    "\n",
    "Welcome to the final part of the \"Artificial Intelligence for Medicine\" course 1!\n",
    "\n",
    "You will learn how to build a neural network to automatically segment tumor regions in brain, using [MRI (Magnetic Resonance Imaging)](https://en.wikipedia.org/wiki/Magnetic_resonance_imaging) scans.\n",
    "\n",
    "The MRI scan is one of the most common image modalities that we encounter in the radiology field.  Other data modalities include: \n",
    "- [Computer Tomography (CT)](https://en.wikipedia.org/wiki/CT_scan), \n",
    "- [Ultrasound](https://en.wikipedia.org/wiki/Ultrasound)\n",
    "- [X-Rays](https://en.wikipedia.org/wiki/X-ray). \n",
    "\n",
    "In this assignment we will be focusing on MRIs but many of our learnings applies to other mentioned modalities as well.  We'll walk you through some of the steps of training a deep learning model for segmentation.\n",
    "\n",
    "**You will learn:**\n",
    "- What is in an MR image\n",
    "- Standard data preparation techniques for MRI datasets\n",
    "- Metrics and loss functions for segmentation\n",
    "- Visualizing and evaluating segmentation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [0. Packages](#0)\n",
    "- [1. Dataset](#1)\n",
    "  - [1.1 What is an MRI?](#1-1)\n",
    "  - [1.2 MRI Data Processing](#1-2)\n",
    "  - [1.3 Exploring the Dataset](#1-3)\n",
    "  - [1.4 Data Preprocessing using Patches](#1-4)\n",
    "    - [Exercise 1 - get_sub_volume](#ex-1)\n",
    "    - [Exercise 2 - standardization](#ex-2)\n",
    "- [2. 3D U-Net Model](#2)\n",
    "- [3. Metrics](#3)\n",
    "  - [3.1 Dice Coefficient](#3-1)\n",
    "    - [Exercise 3 - single_class_dice_coefficient](#ex-3)\n",
    "    - [3.1.1 Dice Coefficient for Multiple Classes](#3-1-1)\n",
    "      - [Exercise 4 - dice_coefficient](#ex-4)\n",
    "  - [3.2 Soft Dice Loss](#3-2)\n",
    "    - [3.2.1 Multi-Class Soft Dice Loss](#3-2-1)\n",
    "      - [Exercise 5 - soft_dice_loss](#ex-5)\n",
    "- [4. Create and Train the Model](#4)\n",
    "  - [4.1 Training on a Large Dataset](#4-1)\n",
    "  - [4.2 Loading a Pre-Trained Model](#4-2)\n",
    "- [5. Evaluation](#5)\n",
    "  - [5.1 Overall Performance](#5-1)\n",
    "  - [5.2 Patch-level Predictions](#5-2)\n",
    "    - [5.2.1 Sensitivity and Specificity](#5-2-1)\n",
    "      - [Exercise 6 - compute_class_sens_spec](#ex-6)\n",
    "  - [5.3 Running on Entire Scans](#5-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Packages <a name=\"0\"></a>\n",
    "We'll use keras, nibabel, numpy, pandas, matplotlib, tensorflow.keras.backend (K), and some provided utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import keras\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "import util\n",
    "from public_tests import *\n",
    "from test_utils import *\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset <a name=\"1\"></a>\n",
    "### 1.1 What is an MRI? <a name=\"1-1\"></a>\n",
    "MRI is a 3D imaging technique. Each voxel can have multiple sequences. We'll segment edemas, non-enhancing tumors, and enhancing tumors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "HOME_DIR = \"data/BraTS-Data/\"\n",
    "DATA_DIR = HOME_DIR\n",
    "\n",
    "def load_case(image_nifty_file, label_nifty_file):\n",
    "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
    "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
    "    return image, label"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize a case\n",
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "image = util.get_labeled_image(image, label)\n",
    "util.plot_image_grid(image)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Animated gif of MRI\n",
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "util.visualize_data_gif(util.get_labeled_image(image, label))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Preprocessing using Patches <a name=\"1-4\"></a>\n",
    "We'll extract random patches and do standardization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNQ_C1\n",
    "def get_sub_volume(image, label, orig_x=240, orig_y=240, orig_z=155, output_x=160, output_y=160, output_z=16, num_classes=4, max_tries=1000, background_threshold=0.95):\n",
    "    X = None\n",
    "    y = None\n",
    "    tries = 0\n",
    "    while tries < max_tries:\n",
    "        start_x = np.random.randint(0, orig_x - output_x + 1)\n",
    "        start_y = np.random.randint(0, orig_y - output_y + 1)\n",
    "        start_z = np.random.randint(0, orig_z - output_z + 1)\n",
    "        y = label[start_x:start_x+output_x, start_y:start_y+output_y, start_z:start_z+output_z]\n",
    "        y = keras.utils.to_categorical(y, num_classes=num_classes)\n",
    "        bgrd_ratio = np.sum(y[:, :, :, 0]) / (output_x * output_y * output_z)\n",
    "        tries += 1\n",
    "        if bgrd_ratio < background_threshold:\n",
    "            X = np.copy(image[start_x:start_x+output_x, start_y:start_y+output_y, start_z:start_z+output_z, :])\n",
    "            X = np.transpose(X, (3, 0, 1, 2))\n",
    "            y = np.transpose(y, (3, 0, 1, 2))\n",
    "            y = y[1:, :, :, :]\n",
    "            return X, y\n",
    "    print(f\"Tried {tries} times to find a sub-volume. Giving up...\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "get_sub_volume_test(get_sub_volume)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_001.nii.gz\", DATA_DIR + \"labelsTr/BRATS_001.nii.gz\")\n",
    "X, y = get_sub_volume(image, label)\n",
    "util.visualize_patch(X[0, :, :, :], y[2])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNQ_C2\n",
    "def standardize(image):\n",
    "    standardized_image = np.zeros_like(image)\n",
    "    for c in range(image.shape[0]):\n",
    "        for z in range(image.shape[3]):\n",
    "            image_slice = image[c, :, :, z]\n",
    "            centered = image_slice - np.mean(image_slice)\n",
    "            if np.std(centered) != 0:\n",
    "                centered_scaled = centered / np.std(centered)\n",
    "            else:\n",
    "                centered_scaled = centered\n",
    "            standardized_image[c, :, :, z] = centered_scaled\n",
    "    return standardized_image"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "standardize_test(standardize, X)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_norm = standardize(X)\n",
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 3D U-Net Model <a name=\"2\"></a>\n",
    "We'll use util.unet_model_3d(loss_function) to build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metrics <a name=\"3\"></a>\n",
    "### 3.1 Dice Similarity Coefficient <a name=\"3-1\"></a>\n",
    "#### Exercise 3 - single_class_dice_coefficient <a name=\"ex-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNQ_C3\n",
    "def single_class_dice_coefficient(y_true, y_pred, axis=(0, 1, 2), epsilon=0.00001):\n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) + epsilon\n",
    "    dice_coefficient = dice_numerator / dice_denominator\n",
    "    return dice_coefficient"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "epsilon = 1\n",
    "sess = K.get_session()\n",
    "single_class_dice_coefficient_test(single_class_dice_coefficient, epsilon, sess)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Dice Coefficient for Multiple Classes <a name=\"3-1-1\"></a>\n",
    "#### Exercise 4 - dice_coefficient <a name=\"ex-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNQ_C4\n",
    "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), epsilon=0.00001):\n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) + epsilon\n",
    "    dice_coefficient = K.mean(dice_numerator / dice_denominator)\n",
    "    return dice_coefficient"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "epsilon = 1\n",
    "sess = K.get_session()\n",
    "dice_coefficient_test(dice_coefficient, epsilon, sess)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Soft Dice Loss <a name=\"3-2\"></a>\n",
    "#### Exercise 5 - soft_dice_loss <a name=\"ex-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNQ_C5\n",
    "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), epsilon=0.00001):\n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true ** 2, axis=axis) + K.sum(y_pred ** 2, axis=axis) + epsilon\n",
    "    dice_loss = 1 - K.mean(dice_numerator / dice_denominator)\n",
    "    return dice_loss"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "epsilon = 1\n",
    "sess = K.get_session()\n",
    "soft_dice_loss_test(soft_dice_loss, epsilon, sess)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and Train the Model <a name=\"4\"></a>\n",
    "We'll use util.unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = util.unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_dir = HOME_DIR + \"processed/\"\n",
    "with open(base_dir + \"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "train_generator = util.VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
    "valid_generator = util.VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=3, dim=(160, 160, 16), verbose=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.load_weights(HOME_DIR + \"model_pretrained.hdf5\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation <a name=\"5\"></a>\n",
    "### 5.2 Patch-level Predictions <a name=\"5-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=0)\n",
    "patch_pred = model.predict(X_norm_with_batch_dimension)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "threshold = 0.5\n",
    "patch_pred[patch_pred > threshold] = 1.0\n",
    "patch_pred[patch_pred <= threshold] = 0.0"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Patch and ground truth\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], y[2])\n",
    "plt.show()\n",
    "print(\"Patch and prediction\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], patch_pred[0, 2, :, :, :])\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Sensitivity and Specificity <a name=\"5-2-1\"></a>\n",
    "##### Exercise 6 - compute_class_sens_spec <a name=\"ex-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UNQ_C6\n",
    "def compute_class_sens_spec(pred, label, class_num):\n",
    "    class_pred = pred[class_num]\n",
    "    class_label = label[class_num]\n",
    "    tp = np.sum((class_label == 1) & (class_pred == 1))\n",
    "    tn = np.sum((class_label == 0) & (class_pred == 0))\n",
    "    fp = np.sum((class_label == 0) & (class_pred == 1))\n",
    "    fn = np.sum((class_label == 1) & (class_pred == 0))\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    return sensitivity, specificity"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "compute_class_sens_spec_test(compute_class_sens_spec)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sensitivity, specificity = compute_class_sens_spec(patch_pred[0], y, 2)\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_sens_spec_df(pred, label):\n",
    "    patch_metrics = pd.DataFrame(\n",
    "        columns=['Edema', 'Non-Enhancing Tumor', 'Enhancing Tumor'],\n",
    "        index=['Sensitivity', 'Specificity'])\n",
    "    for i, class_name in enumerate(patch_metrics.columns):\n",
    "        sens, spec = compute_class_sens_spec(pred, label, i)\n",
    "        patch_metrics.loc['Sensitivity', class_name] = round(sens, 4)\n",
    "        patch_metrics.loc['Specificity', class_name] = round(spec, 4)\n",
    "    return patch_metrics"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = get_sens_spec_df(patch_pred[0], y)\n",
    "print(df)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Running on Entire Scans <a name=\"5-3\"></a>\n",
    "To run on whole scans, see util.predict_and_viz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's all for now!\n",
    "Congratulations on finishing this challenging assignment! You now know all the basics for building a neural auto-segmentation model for MRI images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7"
  },
  "title": "Brain Tumor Auto-Segmentation for MRI"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}